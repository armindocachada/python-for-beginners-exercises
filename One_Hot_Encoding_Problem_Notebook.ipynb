{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0-KoRtHaWQx"
   },
   "source": [
    "# One Hot Encoding Python Problem\n",
    "\n",
    "In today's Python exercise we will create a one-hot encoding algorithm to convert categorical data to numerical format. \n",
    "\n",
    "The reason why we need to do this is because machine learning algorithms only can deal with numbers, not strings.\n",
    "\n",
    "## What is One Hot Encoding?\n",
    "\n",
    "**One-hot encoding** is a way of representing categorical information in binary format, but in such a way that only one digit in the binary number is set to 1. This why it is called one-hot, because only one bit is ON at any time in the binary number.\n",
    "The type of categorical data we are talking about is the type where order is not applicable(nominal). \n",
    "\n",
    "If the category has a natural order, for instance (Day of the Week:  Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday), then you don't need to use one-hot encoding. You can just assign an integer to each day of the week starting from zero.\n",
    "\n",
    "In general its a bad idea to assign an ordinal value to a category which nominal( e.g. cat or dog) as the machine learning algorithm will assume that there is a natural order in the category.  \n",
    "\n",
    "In this video I am going to show you several ways of creating one hot encodings for different types of data that you might come across.\n",
    "\n",
    "First let's just see a simple example of one-hot-encoding\n",
    "\n",
    "this number we have the length of our binary number:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZiMiiZBaTFb"
   },
   "outputs": [],
   "source": [
    "categories=[\"cat\", \"fox\", \"badger\", \"person\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJtDbCbdoFHe"
   },
   "source": [
    "As you can see this category is nominal, meaning that there is no natural order that can be applied. So this is a good candidate to use one hot encoding.\n",
    "\n",
    "To apply this algorithm, we need to count the number of elements in the category. And with this we will have the length of our binary number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3VvNFAaoNnS",
    "outputId": "d615828a-f750-4e71-d478-c279250343ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "length_of_binary_number = len(categories)\n",
    "print(length_of_binary_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZvec4kFos5_"
   },
   "source": [
    "# Manual One-Hot-Encoding\n",
    "\n",
    "To represent this category using One-Hot-Encoding we could then simply define manually each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rtj9LMjhoUzj",
    "outputId": "8aa494ce-4675-4bcc-94ee-3aebd921d47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 8, 'fox': 4, 'badger': 2, 'person': 1}\n"
     ]
    }
   ],
   "source": [
    "one_hot_encodings = dict()\n",
    "\n",
    "one_hot_encodings[\"cat\"] = 0b1000\n",
    "one_hot_encodings[\"fox\"] = 0b0100\n",
    "one_hot_encodings[\"badger\"] = 0b0010\n",
    "one_hot_encodings[\"person\"] = 0b0001\n",
    "\n",
    "print(one_hot_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbSbk0-_oY43"
   },
   "source": [
    "You will notice that we didn't assign 0b0000 to any of the elements. That was on purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEyIiwEaJcU1"
   },
   "source": [
    "# One-Hot-Encoding for larger categories\n",
    "\n",
    "To encode categories with a small number of elements, its ok to do it manually and using just a binary number. But when you are dealing with larger categories with thousands of items, representing a all the possible items using just a binary number is not possible. \n",
    "\n",
    "Consider for instance a 32-bit integer, which is what a computer will typically use to store an integer. \n",
    "\n",
    "One-hot encoding only allows us to use one bit to represent an item in a category. So if we are limited to a 32-bit number we can encode a category with a maximum of 32 elements!\n",
    "\n",
    "To represent categories with a large number of items, we need to use arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6edBCqrK2uO"
   },
   "source": [
    "# Encoding the words in the bible using one-hot encoding\n",
    "\n",
    "In this exercise we are going to use a numpy array to store the features in one-hot encoding format resulting from finding every word that is different in the english text of Genesis.\n",
    "\n",
    "First we download the text from genesis using the HTTP Request library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y72ABg0ovNeN",
    "outputId": "cfc07125-d5a5-467e-c004-6dd7303043a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First Book of Moses called\n",
      "\n",
      "GENESIS\n",
      "\n",
      "1:1: In the beginning God created the heaven and the earth.\n",
      "1:2: And the earth was without form, and void; and darkness was upon the face of the deep.  And the Spirit of God moved upon the face of the waters.\n",
      "1:3: And God said, Let there be light: and there was light.\n",
      "1:4: And God saw the light, that it was good: and God divided the light from the darkness.\n",
      "1:5: And God called the light Day, and the darkness he called Night.  And the evening and the morning were the first day.\n",
      "1:6: And God said, Let there be a firmament in the midst of the waters, and let it divide the waters from the waters.\n",
      "1:7: And God made the firmament, and divided the waters which were under the firmament from the waters which were above the firmament: and it was so.\n",
      "1:8: And God called the firmament Heaven.  And the evening and the morning were the second day.\n",
      "1:9: And God said, Let the waters under the heaven be gathered together unto one place, and let the dry land appear: and it was so.\n",
      "1:10: And God called the dry land Earth; and the gathering together of the waters called he Seas: and God saw that it was good.\n",
      "1:11: And God said, Let the earth bring forth grass, the herb yielding seed, and the fruit tree yielding fruit after his kind, whose seed is in itself, upon the earth: and it was so.\n",
      "1:12: And the earth brought forth grass, and herb yielding seed after his kind, and the tree yielding fruit, whose seed was in itself, after his kind: and God saw that it was good. \n",
      "1:13: And the evening and the morning were the third day.\n",
      "1:14: And God said, Let there be lights in the firmament of the heaven to divide the day from the night; and let them be for signs, and for seasons, and for days, and years: \n",
      "1:15: And let them be for lights in the firmament of the heaven to give light upon the earth: and it was so. \n",
      "1:16: And God made two great lights; the greater light to rule the day, and the lesser light to rule the night: he made the stars also.\n",
      "1:17: And\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"http://www.stewartonbibleschool.org/bible/text/genesis.txt\", stream = True)\n",
    "\n",
    "  # Check if the image was retrieved successfully\n",
    "if r.status_code == 200:\n",
    "    bible_genesis_text = r.text\n",
    "    print(bible_genesis_text[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88ab_8c7Yil0"
   },
   "source": [
    "# Removing verse numbers using Python regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXGyHBYQOFoL"
   },
   "source": [
    "We are going to do some very light data cleansing. Something you are expected to do in any data science project.\n",
    "\n",
    "Now we need to iterate through each verse in Generis,  being careful to discard the verse numbers. We do not want these for the one-hot encoding. \n",
    "\n",
    "Since the length of the verse number differs, we can't just remove a fixed number of characters from each line.\n",
    "\n",
    "This is a great place to use a simple regular expressions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NQYx95CTo0j",
    "outputId": "da4f573a-140e-4a04-def6-930cc16e6bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First Book of Moses called\n",
      "\n",
      "GENESIS\n",
      "\n",
      " In the beginning God created the heaven and the earth.\n",
      " And the earth was without form, and void; and darkness was upon the face of the deep.  And the Spirit of God moved upon the face of the waters.\n",
      " And God said, Let there be light: and there was light.\n",
      " And God saw the light, that it was good: and God divided the light from the darkness.\n",
      " And God called the light Day, and the darkness he called Night.  And the evening and the morning were the first day.\n",
      " And God said, Let there be a firmament in the midst of the waters, and let it divide the waters from the waters.\n",
      " And God made the firmament, and divided the waters which were under the firmament from the waters which were above the firmament: and it was so.\n",
      " And God called the firmament Heaven.  And the evening and the morning were the second day.\n",
      " And God said, Let the waters under the heaven be gathered together unto one place, and let the dry land appear: and it was so.\n",
      " And God called the dry land Earth; and the gathering together of the waters called he Seas: and God saw that it was good.\n",
      " And God said, Let the earth bring forth grass, the herb yielding seed, and the fruit tree yielding fruit after his kind, whose seed is in itself, upon the earth: and it was so.\n",
      " And the earth brought forth grass, and herb yielding seed after his kind, and the tree yielding fruit, whose seed was in itself, after his kind: and God saw that it was good. \n",
      " And the evening and the morning were the third day.\n",
      " And God said, Let there be lights in the firmament of the heaven to divide the day from the night; and let them be for signs, and for seasons, and for days, and years: \n",
      " And let them be for lights in the firmament of the heaven to give light upon the earth: and it was so. \n",
      " And God made two great lights; the greater light to rule the day, and the lesser light to rule the night: he made the stars also.\n",
      " And God set them in the firmament of the heaven to give light upon the earth,\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lines =  bible_genesis_text.splitlines()\n",
    "\n",
    "verses_without_number=\"\"\n",
    "for line in lines:\n",
    "  verse_without_number = re.sub(\"\\d+:\\d+:\", \"\", line )\n",
    "  verses_without_number += (verse_without_number + \"\\n\")\n",
    "\n",
    "print(verses_without_number[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W-HR6zqZLEm"
   },
   "source": [
    "# Creating a numpy array with a one-hot encoding for each verse in Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdzwJz2DZXYv",
    "outputId": "f80f28c0-3437-400b-8050-022619c02164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'First', 'Book', 'of', 'Moses', 'called', 'GENESIS', 'In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth.', 'And', 'the', 'earth', 'was', 'without', 'form,', 'and', 'void;']\n"
     ]
    }
   ],
   "source": [
    "print(verses_without_number.split()[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IONtfkAbfFC9"
   },
   "source": [
    "Notice we still have punctuation in each word. We don't want it!\n",
    "Luckily we don't need to come up with a regex for that. Python has a secret up its sleeves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "a7FREgXwfPWx",
    "outputId": "6c0869c9-7dac-4564-c321-091229e1a820"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flvab_v6fv5X"
   },
   "source": [
    "If we import the string library we have access to a handy attribute, which contains all the punctuation characters that you will normally find in a text.\n",
    "\n",
    "Using str.strip() we can then remove all the punctuation from our words before applying one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kPV4qbPgdkB",
    "outputId": "12f2bc9b-f664-490f-ef38-97a3d39d6a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "First\n",
      "Book\n",
      "of\n",
      "Moses\n",
      "called\n",
      "GENESIS\n",
      "In\n",
      "the\n",
      "beginning\n",
      "God\n",
      "created\n",
      "the\n",
      "heaven\n",
      "and\n",
      "the\n",
      "earth\n",
      "And\n",
      "the\n",
      "earth\n",
      "was\n",
      "without\n",
      "form\n",
      "and\n",
      "void\n"
     ]
    }
   ],
   "source": [
    "for word in verses_without_number.split()[0:25]:\n",
    "  word_without_punctuuation = word.strip(string.punctuation)\n",
    "  print(word_without_punctuuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpgDX3ERhsaD"
   },
   "source": [
    "# Generating One-hot encoding using Numpy Arrays\n",
    "\n",
    "Now that we have cleansed our data we are ready to generate our one-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3eGAhjzxhygg",
    "outputId": "51eb2f04-2777-4514-84ad-fcdc156fd322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 0),\n",
       " ('First', 1),\n",
       " ('Book', 2),\n",
       " ('of', 1799),\n",
       " ('Moses', 4),\n",
       " ('called', 1413),\n",
       " ('GENESIS', 6),\n",
       " ('In', 7),\n",
       " ('the', 1056),\n",
       " ('beginning', 2331)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_index= {}\n",
    "words_in_genesis_list = verses_without_number.split()\n",
    "\n",
    "for word in words_in_genesis_list:\n",
    "  word_without_punctuation = word.strip(string.punctuation)\n",
    "  if word not in words_index:\n",
    "    words_index[word_without_punctuation] = len(words_index)\n",
    "list(words_index.items())[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM3RXIngmgmD"
   },
   "source": [
    "Now it is time to generate one-hot encodings using Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIqCLx84ogDG",
    "outputId": "911ce7b5-18a1-4953-a5dc-09760c512fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38267, 2670)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result = np.zeros((len(words_in_genesis_list), len(words_index)))\n",
    "for index, word in enumerate(words_in_genesis_list):\n",
    "  word_without_punctuation = word.strip(string.punctuation)\n",
    "  hot_index = words_index[word_without_punctuation]\n",
    "  result[index][hot_index-1] = 1\n",
    "\n",
    "print(result.shape)\n",
    "result[0:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI_V1L4JO0aw"
   },
   "source": [
    "# One-hot Encoding with Pandas\n",
    "\n",
    "Since One-hot encoding is used quite often in Data Science, you will find that it is implemented already for you in the most popular data science libraries.\n",
    "\n",
    "In the Pandas library you can apply One-hot encoding to a column in a Panda data frame using the get_dummies() method.\n",
    "\n",
    "First let's create a Panda Data Frame with a single column from our existing data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "flPRvlgaO7gd",
    "outputId": "21e66a3d-0ca0-44d4-9fdb-672314d0f4e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ca77e0af-a740-4c9a-bfb2-c36b47587cc1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38262</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38263</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38264</th>\n",
       "      <td>coffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38265</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38267 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca77e0af-a740-4c9a-bfb2-c36b47587cc1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ca77e0af-a740-4c9a-bfb2-c36b47587cc1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ca77e0af-a740-4c9a-bfb2-c36b47587cc1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Word\n",
       "0         The\n",
       "1       First\n",
       "2        Book\n",
       "3          of\n",
       "4       Moses\n",
       "...       ...\n",
       "38262      in\n",
       "38263       a\n",
       "38264  coffin\n",
       "38265      in\n",
       "38266   Egypt\n",
       "\n",
       "[38267 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# we use a lambda function and map to strip all the punctuation\n",
    "words_in_genesis_list = list(map( lambda x: x.strip(string.punctuation), words_in_genesis_list))\n",
    "df = pd.DataFrame(words_in_genesis_list, columns=[\"Word\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ00M0ZIVgbC"
   },
   "source": [
    "To Apply One-Hot encoding we simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "A6GMhJYKRn6m",
    "outputId": "c74ebd24-9d41-4414-dc67-58d56db85f19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-63a1a90a-b385-463a-8002-14b472f35a6c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_A</th>\n",
       "      <th>word_Abel</th>\n",
       "      <th>word_Abel-mizraim</th>\n",
       "      <th>word_Abida</th>\n",
       "      <th>word_Abide</th>\n",
       "      <th>word_Abimael</th>\n",
       "      <th>word_Abimelech</th>\n",
       "      <th>word_Abimelech's</th>\n",
       "      <th>word_Abraham</th>\n",
       "      <th>word_Abraham's</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yoke</th>\n",
       "      <th>word_yonder</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_young</th>\n",
       "      <th>word_younger</th>\n",
       "      <th>word_youngest</th>\n",
       "      <th>word_your</th>\n",
       "      <th>word_yours</th>\n",
       "      <th>word_yourselves</th>\n",
       "      <th>word_youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38267 rows × 2670 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63a1a90a-b385-463a-8002-14b472f35a6c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-63a1a90a-b385-463a-8002-14b472f35a6c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-63a1a90a-b385-463a-8002-14b472f35a6c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       word_A  word_Abel  word_Abel-mizraim  word_Abida  word_Abide  \\\n",
       "0           0          0                  0           0           0   \n",
       "1           0          0                  0           0           0   \n",
       "2           0          0                  0           0           0   \n",
       "3           0          0                  0           0           0   \n",
       "4           0          0                  0           0           0   \n",
       "...       ...        ...                ...         ...         ...   \n",
       "38262       0          0                  0           0           0   \n",
       "38263       0          0                  0           0           0   \n",
       "38264       0          0                  0           0           0   \n",
       "38265       0          0                  0           0           0   \n",
       "38266       0          0                  0           0           0   \n",
       "\n",
       "       word_Abimael  word_Abimelech  word_Abimelech's  word_Abraham  \\\n",
       "0                 0               0                 0             0   \n",
       "1                 0               0                 0             0   \n",
       "2                 0               0                 0             0   \n",
       "3                 0               0                 0             0   \n",
       "4                 0               0                 0             0   \n",
       "...             ...             ...               ...           ...   \n",
       "38262             0               0                 0             0   \n",
       "38263             0               0                 0             0   \n",
       "38264             0               0                 0             0   \n",
       "38265             0               0                 0             0   \n",
       "38266             0               0                 0             0   \n",
       "\n",
       "       word_Abraham's  ...  word_yoke  word_yonder  word_you  word_young  \\\n",
       "0                   0  ...          0            0         0           0   \n",
       "1                   0  ...          0            0         0           0   \n",
       "2                   0  ...          0            0         0           0   \n",
       "3                   0  ...          0            0         0           0   \n",
       "4                   0  ...          0            0         0           0   \n",
       "...               ...  ...        ...          ...       ...         ...   \n",
       "38262               0  ...          0            0         0           0   \n",
       "38263               0  ...          0            0         0           0   \n",
       "38264               0  ...          0            0         0           0   \n",
       "38265               0  ...          0            0         0           0   \n",
       "38266               0  ...          0            0         0           0   \n",
       "\n",
       "       word_younger  word_youngest  word_your  word_yours  word_yourselves  \\\n",
       "0                 0              0          0           0                0   \n",
       "1                 0              0          0           0                0   \n",
       "2                 0              0          0           0                0   \n",
       "3                 0              0          0           0                0   \n",
       "4                 0              0          0           0                0   \n",
       "...             ...            ...        ...         ...              ...   \n",
       "38262             0              0          0           0                0   \n",
       "38263             0              0          0           0                0   \n",
       "38264             0              0          0           0                0   \n",
       "38265             0              0          0           0                0   \n",
       "38266             0              0          0           0                0   \n",
       "\n",
       "       word_youth  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "38262           0  \n",
       "38263           0  \n",
       "38264           0  \n",
       "38265           0  \n",
       "38266           0  \n",
       "\n",
       "[38267 rows x 2670 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[\"Word\"], prefix=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H794GZMTV2VG"
   },
   "source": [
    "We have added a massive amount of columns to the panda table. Obviously this is not for human consumption. But for machine learning algorithm, this is exactly what it needs to make some sense of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQzes2r5WGCg"
   },
   "source": [
    "# One-Hot encoding with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFLOrWTOQta2",
    "outputId": "65b8b42c-7300-46dd-fdd0-2af54c5cfd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 600  208  102 ...  973 1535  159]\n",
      "The One-Hot-Encoded verses\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(38267, 2670)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "sk_words_index = labelEncoder.fit_transform(words_in_genesis_list)\n",
    "print(sk_words_index)\n",
    "onehotEnc = preprocessing.OneHotEncoder()\n",
    "onehotEnc.fit(sk_words_index.reshape(-1, 1))\n",
    "one_hot_encoded_words = onehotEnc.transform(sk_words_index.reshape(-1, 1))\n",
    "\n",
    "print(\"The One-Hot-Encoded verses\")\n",
    "print(one_hot_encoded_words.toarray())\n",
    "print(one_hot_encoded_words.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByOwyy1QbaBu"
   },
   "source": [
    "# One Hot Encoding with Keras\n",
    "\n",
    "One-hot-encoding with Keras comes with a few extra functionalities. For instance, by default all words are converted to lowercase to avoid duplicate words being treated differently. Also you can specify the maximum number of words that you want to consider to build a word_index, based on word frequency. This can be useful if you are looking to remove outliers. You can also customise the filter of words that Keras uses to strip unwanted characters from the text(i.e. punctuation, numbers, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeAKZXPEbd-r"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    lower=False,\n",
    "    num_words=None\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(words_in_genesis_list)\n",
    "#sequences = tokenizer.texts_to_sequences(verses_without_number_list)\n",
    "one_hot_results = tokenizer.texts_to_matrix(words_in_genesis_list, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZ99BucKZ0OM",
    "outputId": "8a8f56ec-5502-49fc-be2e-89c8b415832b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38267, 2686)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkR4I-crep3N"
   },
   "source": [
    "# Interesting that the results fromt he Keras One-Hot-Encoding differ slighly from the other results. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RI7bEQ_ueQxp",
    "outputId": "76a925ef-3c7b-4dee-acfe-f45e6031fba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tubal-cain\n",
      "Hazar-maveth\n",
      "El-paran\n",
      "En-mishpat\n",
      "Hazezon-tamar\n",
      "Beer-lahai-roi\n",
      "Beer-sheba\n",
      "Jehovah-jireh\n",
      "Kirjath-arba\n",
      "Lahai-roi\n",
      "Padan-aram\n",
      "Jegar-sahadutha\n",
      "El-elohe-Israel\n",
      "El-beth-el\n",
      "Allon-bachuth\n",
      "Ben-oni\n",
      "Baal-hanan\n",
      "Zaphnath-paaneah\n",
      "Poti-pherah\n",
      "Abel-mizraim\n"
     ]
    }
   ],
   "source": [
    "keras_word_index = tokenizer.word_index\n",
    "\n",
    "for word in words_index:\n",
    "  if word not in keras_word_index:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z8BMJpReyP8"
   },
   "source": [
    "Aha. Seems like Keras treats words with a dash(-) a bit differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QeIxDyXfJ_a",
    "outputId": "8f444ee4-2288-4584-dd1e-8e558addaa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beer\n",
      "sheba\n",
      "aram\n",
      "El\n",
      "roi\n",
      "Poti\n",
      "pherah\n",
      "cain\n",
      "Lahai\n",
      "Baal\n",
      "hanan\n",
      "Hazar\n",
      "maveth\n",
      "paran\n",
      "En\n",
      "mishpat\n",
      "Hazezon\n",
      "tamar\n",
      "lahai\n",
      "Jehovah\n",
      "jireh\n",
      "Kirjath\n",
      "arba\n",
      "Jegar\n",
      "sahadutha\n",
      "elohe\n",
      "beth\n",
      "el\n",
      "Allon\n",
      "bachuth\n",
      "Ben\n",
      "oni\n",
      "Zaphnath\n",
      "paaneah\n",
      "mizraim\n"
     ]
    }
   ],
   "source": [
    "keras_word_index = tokenizer.word_index\n",
    "\n",
    "for word in keras_word_index:\n",
    "  if word not in words_index:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LVVG1kofX4S"
   },
   "source": [
    "I think the culprit is the filter list, which is stripping all the -. Let's remove - from the filters property and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYq008Befbvq",
    "outputId": "c426943e-a157-4bd6-84c6-659c2943ff97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38267, 2671)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    lower=False,\n",
    "    num_words=None,\n",
    "    filters='!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    split=' '\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(words_in_genesis_list)\n",
    "#sequences = tokenizer.texts_to_sequences(verses_without_number_list)\n",
    "one_hot_results = tokenizer.texts_to_matrix(words_in_genesis_list, mode='binary')\n",
    "one_hot_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn_3Tc9XktDZ"
   },
   "source": [
    "Seems like we still have an extra column in the Keras word index( 2671 vs 2670 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v72U3NDhgc-Z"
   },
   "outputs": [],
   "source": [
    "keras_word_index = tokenizer.word_index\n",
    "\n",
    "for word in keras_word_index:\n",
    "  if word not in words_index:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtWUqeIJhEes",
    "outputId": "d21d76a2-c4a6-4a5f-c3eb-15a68ce83619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670\n",
      "2670\n"
     ]
    }
   ],
   "source": [
    "for word in words_index:\n",
    "  if word not in keras_word_index:\n",
    "    print(word)\n",
    "\n",
    "print(len(keras_word_index))\n",
    "print(len(words_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kASouznvhBs8"
   },
   "source": [
    "The index of words seems to be identical. But why the extra column?\n",
    "The clue is in the Keras documentation. It seems that they use index 0 for internal use. Hence none of the words have the first column assigned to 1."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "One Hot Encoding Problem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
